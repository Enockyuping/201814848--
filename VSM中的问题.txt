1、去除符号时英文的单引号和“-”号是否要去除
2、分词时使用split（）函数是否更简单
3、(优化)去除停用词时是使用nltk还是使用自己建的停用词表（停用词表中未包含分词时分得很小或很不规则的词，有的都不是单词）
   如果使用自己的停用词表，是否需要将停用词表先进行一次词干提取
4、在读入所有文档时，若遇到不能识别的文档格式时，用什么方式解码
5\#进行预处理，并将每个文档预处理得到的列表内容加到documents_wordlist中
            documents_wordlist.extend(precessing(document_data))
            此处使用.extend()还是.append()

6、词典的一部分作为新的词典时，取出的那部分起始和结束的值怎么确定（字典的顺序是随机的，是否应该按照词频排序，然后再取出）
7、需要调整的参数：
    为降维以减小计算量，制作词典时，去掉高频词和低频词的界限：使用手动的办法设置词频上下界参数（需要统计除所有的词频）
    在计算IDF时，为防止log函数中最大词频为0，将分母+1
    在计算TF时，选用第一个公式， -𝑡𝑓(𝑡,𝑑)={(1+log⁡𝑐(𝑡,𝑑), 𝑖𝑓 𝑐(𝑡,𝑑)>0     0, 𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒)


